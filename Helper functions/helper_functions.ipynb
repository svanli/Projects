{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d90d12-1edd-4563-a9ff-ed58bd346b81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# __Helper functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b07f93-2ff2-4b25-b861-2a6a2e521f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45132470-7ab1-4172-8a6e-c8d8afb57452",
   "metadata": {},
   "source": [
    "<code>scrollable_output</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b852ca-f09d-498a-84af-6e9a12d20bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def scrollable_output(output_height = 500):\n",
    "    \"\"\"Enable scrollable output.\"\"\"\n",
    "    display(HTML(f\"\"\"\n",
    "    <style>\n",
    "    .jp-OutputArea-output {{\n",
    "        max-height: {output_height}px;\n",
    "        overflow-y: auto;\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23281b7b-91fd-4c46-9a58-5b6b09c6df90",
   "metadata": {},
   "source": [
    "<code>dataset_check</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13ed2d-2ddc-4970-b12f-cc1569925b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataset_check(\n",
    "    dataset,\n",
    "    shape_check = True,\n",
    "    dup_check = True,\n",
    "    dtypes_check = True,\n",
    "    missing_values_check = True,\n",
    "    unique_values_check = True,\n",
    "    unique_values_percentage_check = True,\n",
    "    stats_check = False,\n",
    "    corr_check = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Provides a comprehensive overview of the dataset, including:\n",
    "\n",
    "    * The shape of the dataset (number of rows and columns).\n",
    "    * Detection of duplicate rows.\n",
    "    * Data types of each column.\n",
    "    * Identification of columns with missing values, including the count and percentage of missing values.\n",
    "    * Unique values in each column.\n",
    "    * Percentage of unique values (unique-to-total ratio) for each column.\n",
    "    * Basic statistical summary (e.g., count, mean, standard deviation, minimum, maximum) for numerical columns.\n",
    "    * Correlation matrix between numerical columns.\n",
    "\n",
    "    By default, the function performs all checks except for basic statistics and correlations, which can be enabled with the `stats_check` and `corr_check` parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: The DataFrame to be analyzed.\n",
    "    - shape_check (bool): Whether to print the shape of the dataset.\n",
    "    - dup_check (bool): Whether to check for duplicate rows.\n",
    "    - dtypes_check (bool): Whether to print the data types of each column.\n",
    "    - missing_values_check (bool): Whether to check for missing values.\n",
    "    - unique_values_check (bool): Whether to print the number of unique values in each column.\n",
    "    - unique_values_percentage_check (bool): Whether to print unique-to-total value percentages per column.\n",
    "    - stats_check (bool): Whether to print basic statistics of numerical columns.\n",
    "    - corr_check (bool): Whether to print the correlation matrix of numerical columns.\n",
    "    \"\"\"\n",
    "    # Calculate\n",
    "    df = dataset\n",
    "    columns = df.shape[1]\n",
    "    rows = df.shape[0]\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    dtypes = df.dtypes\n",
    "    missing = df.isna().sum()\n",
    "    missing = missing[missing > 0]\n",
    "    missing_percentage = (df.isna().sum() / len(df) * 100).round(2)\n",
    "    missing_percentage = missing_percentage[missing_percentage > 0]\n",
    "    unique = df.nunique()\n",
    "    unique_percentage = (df.nunique() / len(df)).apply(lambda x: f\"{x:.2%}\")\n",
    "    stats = df.describe() if stats_check else None\n",
    "    corr = df.corr() if corr_check else None\n",
    "\n",
    "    # Print\n",
    "    if shape_check:\n",
    "        print(f'COLUMNS:\\n{columns:,}\\n'.replace(',', ' '))\n",
    "        print(f'ROWS:\\n{rows:,}\\n'.replace(',', ' '))\n",
    "        \n",
    "    if dup_check:\n",
    "        print(f'DUPLICATE ROWS:\\n{duplicate_rows}\\n')\n",
    "\n",
    "    if dtypes_check:\n",
    "        print(f'DATATYPES:\\n{dtypes}\\n')\n",
    "\n",
    "    if missing_values_check:\n",
    "        if missing.empty:\n",
    "            print('MISSING VALUES:\\n0\\n')\n",
    "            print('MISSING VALUES IN %:\\n0%\\n')\n",
    "        else:\n",
    "            print(f'MISSING VALUES:\\n{missing}\\n')\n",
    "            print(f'MISSING VALUES IN %:\\n{missing_percentage.apply(lambda x: f\"{x:.2f}%\")}\\n')\n",
    "\n",
    "    if unique_values_check:    \n",
    "        print(f'UNIQUE VALUES:\\n{unique}\\n')\n",
    "\n",
    "    if unique_values_percentage_check:\n",
    "        print(f'UNIQUE VALUES IN %:\\n{unique_percentage}\\n')\n",
    "        \n",
    "    if stats_check:\n",
    "        print(f'BASIC STATISTICS:\\n{stats}\\n')\n",
    "        \n",
    "    if corr_check:\n",
    "        print(f'CORRELATION MATRIX:\\n{corr}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628482c2-a865-46bc-8a30-6d70acbd70a2",
   "metadata": {},
   "source": [
    "<code>uvalues_check</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79ab8c-252c-4825-9333-4dd86dd68d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uvalues_check(dataset, columns):\n",
    "    \"\"\"\n",
    "    Provides a list of unique values for specified columns in the dataset, sorted alphabetically.\n",
    "\n",
    "    This function takes a dataset and a list of column names, then prints the unique values for each specified column.\n",
    "    The unique values are sorted alphabetically to enhance readability.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: The DataFrame to be analyzed.\n",
    "    - columns: A list of column names for which unique values will be printed.\n",
    "    \n",
    "    Example:\n",
    "    >>> df = pd.DataFrame({'A': [1, 2, 2], 'B': ['x', 'y', 'x']})\n",
    "    >>> uvalues_check(df, ['A', 'B'])\n",
    "    UNIQUE VALUES\n",
    "\n",
    "    A\n",
    "    [1, 2]\n",
    "\n",
    "    B\n",
    "    ['x', 'y']\n",
    "    \"\"\"\n",
    "    print('UNIQUE VALUES\\n')\n",
    "    for column in columns:\n",
    "        print(column.upper())\n",
    "        uvalues = dataset[column].unique()\n",
    "        uvalues_sorted = sorted(uvalues, key = lambda x: str(x).lower())\n",
    "        print(uvalues_sorted, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af6f53e-fe51-4da4-aff5-5c0bbbc9ccf6",
   "metadata": {},
   "source": [
    "<code>text_check</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c22184-3337-425a-847f-3c594623cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_check(dataset, columns):\n",
    "    \"\"\"\n",
    "    Identifies and prints non-numeric values in specified columns of the dataset.\n",
    "\n",
    "    This function examines the specified columns in the provided dataset and identifies values that are not numeric.\n",
    "    It prints out these non-numeric values, sorted alphabetically. If a column contains only numeric values, it indicates this as well.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: The DataFrame to be analyzed.\n",
    "    - columns: A list of column names to be checked for non-numeric values.\n",
    "    \n",
    "    Example:\n",
    "    >>> df = pd.DataFrame({'A': [1, 'two', 3], 'B': ['x', '2', '3.5']})\n",
    "    >>> text_check(df, ['A', 'B'])\n",
    "    NON-NUMERIC VALUES\n",
    "\n",
    "    A\n",
    "    ['two']\n",
    "\n",
    "    B\n",
    "    ['x']\n",
    "    \"\"\"\n",
    "    df = dataset\n",
    "    print('NON-NUMERIC VALUES\\n')\n",
    "    for column in columns:\n",
    "        numeric = pd.to_numeric(df[column], errors = 'coerce')\n",
    "        text_values = df[column][numeric.isna() & df[column].notna()].unique()\n",
    "        text_values_sorted = sorted(text_values, key = lambda x: x.lower())\n",
    "        \n",
    "        if len(text_values_sorted) > 0:\n",
    "            print(column.upper())\n",
    "            print(text_values_sorted, '\\n')\n",
    "        else:\n",
    "            print(column.upper())\n",
    "            print('Numeric values only\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59ca64-5082-43c1-b5a0-4b2f945b5da4",
   "metadata": {},
   "source": [
    "<code>clean_text</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca81a0b-48f0-42f7-81f1-78b00c3139c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def clean_text(dataset, columns):\n",
    "    \"\"\"\n",
    "    Cleans text columns in the specified columns of the dataset by:\n",
    "    - Normalizing Unicode to remove non-standard characters.\n",
    "    - Stripping leading/trailing whitespace.\n",
    "    - Replacing multiple spaces with a single space.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: The DataFrame containing the columns to be cleaned.\n",
    "    - columns: A list of column names to be cleaned.\n",
    "    \n",
    "    Example:\n",
    "    >>> df = pd.DataFrame({'A': ['  hello  ', 'world!'], 'B': [' 123 ', 'abc   ']})\n",
    "    >>> text_clean(df, ['A', 'B'])\n",
    "    \"\"\"\n",
    "    df = dataset\n",
    "\n",
    "    for column in columns:\n",
    "        # Ensure the column is string-like before processing\n",
    "        df[column] = df[column].astype(str)\n",
    "        df[column] = df[column].apply(lambda x: unicodedata.normalize(\"NFKC\", x))  # Normalize Unicode\n",
    "        df[column] = df[column].str.strip()  # Strip leading and trailing whitespace\n",
    "        df[column] = df[column].str.replace(r\"\\s+\", \" \", regex=True)  # Replace multiple spaces with one\n",
    "    return df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
